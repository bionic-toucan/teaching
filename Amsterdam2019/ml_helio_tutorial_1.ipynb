{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ML-Helio Tutorial 1: Preparing data, training models, making inference\n",
    "\n",
    "## John Armstrong, University of Glasgow\n",
    "### 17/09/19, Amsterdam, NL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The following notebook will demonstrate the basics of preparing data to use for machine learning purposes; training various models using different regression methods from the [scikit-learn](https://scikit-learn.org/stable/) Python package and a neural network from the [PyTorch](https://pytorch.org); and making inference on unseen data.\n",
    "\n",
    "The example we will use is that of predicting sunspot numbers for the next solar cycle. The sunspot number data is provided by [Royal Observatory of Belgium](http://sidc.be/silso/datafiles) and we use the data of mean monthly sunspot number. The data spans 1749&ndash;present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The first thing to do is import all of the Python packages we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.gaussian_process.kernels import ExpSineSquared, RBF, ConstantKernel\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. Preparing the Data\n",
    "\n",
    "The data we have is in csv format (it is the file `SN_m_tot_V2.0.csv`). The format of the file is as follows.\n",
    "\n",
    "| Column number | Column contents                               |\n",
    "|:-------------:|-----------------------------------------------|\n",
    "|       1       | Year                                          |\n",
    "|       2       | Month                                         |\n",
    "|       3       | Date in fraction of year                      |\n",
    "|       4       | Monthly mean total number of sunspots         |\n",
    "|       5       | Monthly standard deviation                    |\n",
    "|       6       | Number of observations used to calculate mean |\n",
    "|       7       | Definitive/provisional marker                 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We then want to prepare this data using the `pandas` and `numpy` Python packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_data = pd.read_csv(\"SN_m_tot_V2.0.csv\", sep=\";\", header=None, names=[\"Year\", \"Month\", \"Date in fraction of year\", \"Monthly mean\", \"Monthly standard deviation\", \"Number of observations\", \"Definitive/provisional marker\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can now plot the data to see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(ss_data[\"Date in fraction of year\"], ss_data[\"Monthly mean\"])\n",
    "plt.ylabel(\"Mean monthly sunspot number\")\n",
    "plt.xlabel(\"Year\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "time = ss_data[\"Date in fraction of year\"].to_numpy()\n",
    "ss_number = ss_data[\"Monthly mean\"].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Most ML algorithms in `scitkit-learn` require the features of the data to be standardised and distributed as the unit Gaussian. As such we use the preprocessing technique of `StandardScaler` to define a standard transformation to this ditribution which can then be inverted to return to the original system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "ss.fit(time.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can transform our feature (time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_ss = ss.transform(time.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We now have prepared both the input and the output for our machine learning problem. The next thing to do is to apply some ML methods!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. Applying Machine Learning Methods through Scikit-learn\n",
    "\n",
    "The following will be a demonstration on how to use some of the regression methods from the `scikit-learn` Python package to fit our data and see if we can predict the next solar cycle.\n",
    "\n",
    "Methods from `scikit-learn` follow the same basic recipe:\n",
    "\n",
    "1. Initialise a class instance of the chosen algorithm\n",
    "2. Use the `.fit` class method to train the algorithm\n",
    "3. Use the `.predict` class method to use the trained models for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Both methods we will look at to demonstrate using `scitkit-learn` for machine learning will employ what is known as the **kernel trick**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Typically, ML algorithms need help in fitting non-linear functions. This usually comes in the form of mapping the raw data to a higher-dimensional feature space in which the fit is linear. When the higher-dimensional linear fit is found and transformed to the original data space we have our non-linear fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The kernel trick uses a similarity function to work in an implicit feature space without ever having to transform the data there. This allows us to calculate the inner product on this feature space and fit the non-linear function. This reduces computational complexity and is [mathematically viable](https://en.wikipedia.org/wiki/Kernel_method). For more information on what kernel to choose see [this guide](https://www.cs.toronto.edu/~duvenaud/cookbook/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.1 Support Vector Machines (SVMs)\n",
    "\n",
    "In SVMs for regression, the hyperplane we fit to our data will be used as the function to predict future and past points in our data. This hyperplane is determined by minimising the error between the data and the predicted value to within a certain threshold. Points within the threshold are ignored for moving the position of the fit and the points closest to Â± threshold are the support vectors which give more weight to changing the fit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "An example ([source](https://medium.com/coinmonks/support-vector-regression-or-svr-8eb3acf6d0ff)):\n",
    "\n",
    "![](Pictures/svr.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "svr = SVR(kernel=ConstantKernel(constant_value=10)*(ExpSineSquared(length_scale=0.1, periodicity=1)+RBF(length_scale=0.01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "svr.fit(time_ss, ss_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf = np.linspace(1600,2200,1000)\n",
    "inf_ss = ss.transform(inf.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_fit = svr.predict(inf_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def plot_svr():\n",
    "    plt.figure(figsize=(15,6))\n",
    "    plt.plot(time,ss_number,\".\")\n",
    "    plt.plot(inf, curve_fit)\n",
    "    plt.legend(labels=[\"Data\", \"Fit\"])\n",
    "    plt.ylabel(\"Monthly Mean Sunspot Number\")\n",
    "    plt.xlabel(\"Year\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plot_svr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.2 Kernel Ridge Regression\n",
    "\n",
    "Ridge regression is essentially fitting linear least squares but with an L2 regularisation penalty to help prevent overfitting. Kernerl ridge regression is the same but using the kernel trick to be able to fit non-linear functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "krr = KernelRidge(kernel=ConstantKernel(constant_value=10)*(ExpSineSquared(length_scale=0.1, periodicity=1)+RBF(length_scale=0.01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "krr.fit(time_ss, ss_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_fit_k = krr.predict(inf_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def plot_krr():\n",
    "    plt.figure(figsize=(15,6))\n",
    "    plt.plot(time,ss_number,\".\")\n",
    "    plt.plot(inf, curve_fit_k)\n",
    "    plt.legend(labels=[\"Data\", \"Kernel Ridge Regression\"])\n",
    "    plt.ylabel(\"Monthly Mean Sunspot Number\")\n",
    "    plt.xlabel(\"Year\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plot_krr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A comparison of methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def plot_comp():\n",
    "    plt.figure(figsize=(15,6))\n",
    "    plt.plot(time,ss_number,\".\")\n",
    "    plt.plot(inf, curve_fit_k)\n",
    "    plt.plot(inf, curve_fit)\n",
    "    plt.legend(labels=[\"Data\", \"Kernel Ridge Regression\", \"SVM\"])\n",
    "    plt.ylabel(\"Monthly Mean Sunspot Number\")\n",
    "    plt.xlabel(\"Year\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3. Neural Networks with PyTorch\n",
    "\n",
    "The following section will look at building neural networks with the deep learning framework `PyTorch`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Torch has its own built-in maths library similar to numpy called **torch tensors**. These torch tensors are used as inputs and outputs to the neural networks built with Torch. They can be easily converted from (using the `torch.from_numpy` function) and to (using the `.numpy()` class method) numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros(4)\n",
    "b = torch.from_numpy(a)\n",
    "c = b.numpy()\n",
    "print(type(a), type(b), type(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.1 Building a Neural Network with PyTorch\n",
    "\n",
    "Building a network in PyTorch is like using Lego: we fit the pieces together to become a whole end-to-end network. This is encapsulated by the class `Module` from `torch.nn` library.\n",
    "\n",
    "`Module` is the skeleton class for all networks in PyTorch. A neural network class should always inherit the `Module` class as it comes with useful methods and the all-important `forward` method which is how the data is passed through the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We will build a simple fully-connected model to try and predict the sunspot number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class FCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FCN, self).__init__()\n",
    "        self.fc1 = nn.Linear(135, 1000)\n",
    "        self.fc1b = nn.Linear(1000,1000)\n",
    "        self.fc2 = nn.Linear(1000, 135)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.fc1(x))\n",
    "        out = F.relu(self.fc1b(out))\n",
    "        return self.fc2(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where here `nn.Linear` denotes a fully-connected layer in our neural network and after each layer we use the rectified linear unit (ReLU) non-linearity which can be described by\n",
    "\n",
    "$$ \\phi (x) = \\text{max} (0, x) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](Pictures/mlhelio_fc.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what our neural network looks like. We now need to train the network on our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.2 Training a Neural Network in PyTorch\n",
    "\n",
    "Torch does not come with prebuilt methods like `.fit` in `scitkit-learn`. As a result, we need to build our training and validation functions and give the network the data in a format it understands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "With Torch we utilise the `Dataset` and `DataLoader` classes.\n",
    "\n",
    "* `Dataset` will allow us to format our dataset in a Torch-friendly manner e.g. in terms of Torch tensors.\n",
    "* `DataLoader` will allow us to pass the data to the neural network in a sensible manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In particular, we use what is known as a `TensorDataset` in PyTorch to store our data. This is essentially just multiple tensors stored in the one object so we have one tensor for inputs and another for outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Next we will split our data into a training and validation set. This is beneficial in ML as the validation set contains examples with known answers but the computer has never seen before. This gives a good metric for measuring the capabilities of a network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_rs = time_ss[8:].reshape(24,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_number_rs = ss_number[8:].reshape(24,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(torch.from_numpy(times_rs)[:-2], torch.from_numpy(ss_number_rs)[:-2])\n",
    "val_dataset = TensorDataset(torch.from_numpy(times_rs)[-2:], torch.from_numpy(ss_number_rs)[-2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we create data loaders. This is an object that passes data to the network in batches. This is particularly important on GPUs where the I/O may be the bottleneck of your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = DataLoader(train_dataset, batch_size=64, shuffle=False), DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we have preprocessed our data and can begin to train our network. For training, we must define four things: the number of epochs to train, the learning rate of the system, the optimiser for learning, and the loss function to optimise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcn = FCN()\n",
    "n_epochs = 100\n",
    "lr = 0.005\n",
    "optimiser = optim.Adam(fcn.parameters(), lr=lr)\n",
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where we have chosen to use Adam which is a first order gradient descent method used for quick and accurate optimisation and uses momentum based on the first and second moments of the gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aside: SGD and Optimisation\n",
    "([source](https://towardsdatascience.com/https-medium-com-reina-wang-tw-stochastic-gradient-descent-with-restarts-5f511975163))\n",
    "\n",
    "$ w_{t + 1} = w_{t} + \\eta~ \\nabla L (x; w) $\n",
    "\n",
    "![](Pictures/sgd.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We are now in a position to train our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(n_epochs):\n",
    "    fcn.train()\n",
    "    for inp, out in train_loader:\n",
    "        inp, out = inp.float(), out.float()\n",
    "        optimiser.zero_grad()\n",
    "        model = fcn(inp)\n",
    "        l = loss(model, out)\n",
    "        l.backward()\n",
    "        optimiser.step()\n",
    "        \n",
    "    fcn.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for inp, out in val_loader:\n",
    "            inp, out = inp.float(), out.float()\n",
    "            model = fcn(inp)\n",
    "            l = loss(model, out)\n",
    "            losses.append(l)\n",
    "            \n",
    "    print(\"The validation loss are epoch \"+str(j)+\" is \"+str(np.mean(losses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now it is time to fit the model to the data to see how well it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    curve_fit = fcn(torch.from_numpy(times_rs).float().unsqueeze(0)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_nn():\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(time, ss_number, \".\")\n",
    "    plt.plot(time[8:], curve_fit.reshape(3240))\n",
    "    plt.ylabel(\"Mean sunspot number\")\n",
    "    plt.xlabel(\"Year\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plot_nn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## More Resources 1\n",
    "\n",
    "* [PyTorch tutorials](https://pytorch.org/tutorials/) are **very** good.\n",
    "* [HelioML e-book](http://helioml.org/title.html) for more solar examples &mdash; see Monica Bobra's poster on Thursday!\n",
    "* [scikit-learn examples](https://scikit-learn.org/stable/auto_examples/index.html)\n",
    "* ~shameless self-plug~ [I have a paper with an in-depth introduction to neural networks designed for solar physicists](https://link.springer.com/article/10.1007%2Fs11207-019-1473-z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## More Resources 2\n",
    "\n",
    "* Blog site [Medium](https://medium.com) is very useful for explaining ML concepts in easy to understand ways.\n",
    "* [Deep learning book](http://www.deeplearningbook.org) is good for more of the theory side of things.\n",
    "* [Enrico's book on Machine Learning for Space Weather](https://www.elsevier.com/books/machine-learning-techniques-for-space-weather/camporeale/978-0-12-811788-0)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
